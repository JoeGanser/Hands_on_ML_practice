{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this process, we will use tensor flow to solve for the housing data regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "#identify the shape of the dataset\n",
    "m, n = housing.data.shape\n",
    "\n",
    "#add a bias term for linear regression\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)),housing.data]\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the math behind the least-squares regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#create tensor flow objects that constrain the matrices used in the data\n",
    "X = tf.constant(housing_data_plus_bias,dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X) #transpose of X, used in the theta formula\n",
    "\n",
    "#create the theta used for least squares\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a stochastic gradient descent process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index:  0\n",
      "Epoch 0 MSE =  5.711838\n",
      "batch index:  0\n",
      "Epoch 1 MSE =  5.671631\n",
      "batch index:  0\n",
      "Epoch 2 MSE =  5.632907\n",
      "batch index:  0\n",
      "Epoch 3 MSE =  5.5985513\n",
      "batch index:  0\n",
      "Epoch 4 MSE =  5.567606\n",
      "batch index:  0\n",
      "Epoch 5 MSE =  5.5365086\n",
      "batch index:  0\n",
      "Epoch 6 MSE =  5.5076685\n",
      "batch index:  0\n",
      "Epoch 7 MSE =  5.480321\n",
      "batch index:  0\n",
      "Epoch 8 MSE =  5.4535875\n",
      "batch index:  0\n",
      "Epoch 9 MSE =  5.4304338\n",
      "batch index:  0\n",
      "Epoch 10 MSE =  5.406124\n",
      "batch index:  0\n",
      "Epoch 11 MSE =  5.3842926\n",
      "batch index:  0\n",
      "Epoch 12 MSE =  5.3642025\n",
      "batch index:  0\n",
      "Epoch 13 MSE =  5.3445034\n",
      "batch index:  0\n",
      "Epoch 14 MSE =  5.3256764\n",
      "batch index:  0\n",
      "Epoch 15 MSE =  5.3083878\n",
      "batch index:  0\n",
      "Epoch 16 MSE =  5.2918057\n",
      "batch index:  0\n",
      "Epoch 17 MSE =  5.276025\n",
      "batch index:  0\n",
      "Epoch 18 MSE =  5.2598433\n",
      "batch index:  0\n",
      "Epoch 19 MSE =  5.2457333\n",
      "batch index:  0\n",
      "Epoch 20 MSE =  5.2317567\n",
      "batch index:  0\n",
      "Epoch 21 MSE =  5.2181983\n",
      "batch index:  0\n",
      "Epoch 22 MSE =  5.2056866\n",
      "batch index:  0\n",
      "Epoch 23 MSE =  5.19282\n",
      "batch index:  0\n",
      "Epoch 24 MSE =  5.1808543\n",
      "batch index:  0\n",
      "Epoch 25 MSE =  5.1701264\n",
      "batch index:  0\n",
      "Epoch 26 MSE =  5.1596627\n",
      "batch index:  0\n",
      "Epoch 27 MSE =  5.1492147\n",
      "batch index:  0\n",
      "Epoch 28 MSE =  5.138906\n",
      "batch index:  0\n",
      "Epoch 29 MSE =  5.129474\n",
      "batch index:  0\n",
      "Epoch 30 MSE =  5.120432\n",
      "batch index:  0\n",
      "Epoch 31 MSE =  5.111397\n",
      "batch index:  0\n",
      "Epoch 32 MSE =  5.103802\n",
      "batch index:  0\n",
      "Epoch 33 MSE =  5.0952344\n",
      "batch index:  0\n",
      "Epoch 34 MSE =  5.0873275\n",
      "batch index:  0\n",
      "Epoch 35 MSE =  5.080098\n",
      "batch index:  0\n",
      "Epoch 36 MSE =  5.073107\n",
      "batch index:  0\n",
      "Epoch 37 MSE =  5.0664244\n",
      "batch index:  0\n",
      "Epoch 38 MSE =  5.059879\n",
      "batch index:  0\n",
      "Epoch 39 MSE =  5.053743\n",
      "batch index:  0\n",
      "Epoch 40 MSE =  5.0478096\n",
      "batch index:  0\n",
      "Epoch 41 MSE =  5.042126\n",
      "batch index:  0\n",
      "Epoch 42 MSE =  5.036668\n",
      "batch index:  0\n",
      "Epoch 43 MSE =  5.0315795\n",
      "batch index:  0\n",
      "Epoch 44 MSE =  5.02641\n",
      "batch index:  0\n",
      "Epoch 45 MSE =  5.0212407\n",
      "batch index:  0\n",
      "Epoch 46 MSE =  5.016438\n",
      "batch index:  0\n",
      "Epoch 47 MSE =  5.0120845\n",
      "batch index:  0\n",
      "Epoch 48 MSE =  5.0075116\n",
      "batch index:  0\n",
      "Epoch 49 MSE =  5.003144\n",
      "batch index:  0\n",
      "Epoch 50 MSE =  4.9988194\n",
      "batch index:  0\n",
      "Epoch 51 MSE =  4.9946504\n",
      "batch index:  0\n",
      "Epoch 52 MSE =  4.990544\n",
      "batch index:  0\n",
      "Epoch 53 MSE =  4.986548\n",
      "batch index:  0\n",
      "Epoch 54 MSE =  4.9826837\n",
      "batch index:  0\n",
      "Epoch 55 MSE =  4.9793506\n",
      "batch index:  0\n",
      "Epoch 56 MSE =  4.9756265\n",
      "batch index:  0\n",
      "Epoch 57 MSE =  4.972038\n",
      "batch index:  0\n",
      "Epoch 58 MSE =  4.9691\n",
      "batch index:  0\n",
      "Epoch 59 MSE =  4.9660416\n",
      "batch index:  0\n",
      "Epoch 60 MSE =  4.9626455\n",
      "batch index:  0\n",
      "Epoch 61 MSE =  4.959607\n",
      "batch index:  0\n",
      "Epoch 62 MSE =  4.956533\n",
      "batch index:  0\n",
      "Epoch 63 MSE =  4.953837\n",
      "batch index:  0\n",
      "Epoch 64 MSE =  4.951024\n",
      "batch index:  0\n",
      "Epoch 65 MSE =  4.94846\n",
      "batch index:  0\n",
      "Epoch 66 MSE =  4.9462237\n",
      "batch index:  0\n",
      "Epoch 67 MSE =  4.94381\n",
      "batch index:  0\n",
      "Epoch 68 MSE =  4.9413934\n",
      "batch index:  0\n",
      "Epoch 69 MSE =  4.9389324\n",
      "batch index:  0\n",
      "Epoch 70 MSE =  4.9366493\n",
      "batch index:  0\n",
      "Epoch 71 MSE =  4.934546\n",
      "batch index:  0\n",
      "Epoch 72 MSE =  4.9321904\n",
      "batch index:  0\n",
      "Epoch 73 MSE =  4.930105\n",
      "batch index:  0\n",
      "Epoch 74 MSE =  4.928253\n",
      "batch index:  0\n",
      "Epoch 75 MSE =  4.926186\n",
      "batch index:  0\n",
      "Epoch 76 MSE =  4.92433\n",
      "batch index:  0\n",
      "Epoch 77 MSE =  4.9227257\n",
      "batch index:  0\n",
      "Epoch 78 MSE =  4.920985\n",
      "batch index:  0\n",
      "Epoch 79 MSE =  4.9192853\n",
      "batch index:  0\n",
      "Epoch 80 MSE =  4.917566\n",
      "batch index:  0\n",
      "Epoch 81 MSE =  4.915962\n",
      "batch index:  0\n",
      "Epoch 82 MSE =  4.9142065\n",
      "batch index:  0\n",
      "Epoch 83 MSE =  4.9128118\n",
      "batch index:  0\n",
      "Epoch 84 MSE =  4.911259\n",
      "batch index:  0\n",
      "Epoch 85 MSE =  4.909792\n",
      "batch index:  0\n",
      "Epoch 86 MSE =  4.9083834\n",
      "batch index:  0\n",
      "Epoch 87 MSE =  4.90682\n",
      "batch index:  0\n",
      "Epoch 88 MSE =  4.9053454\n",
      "batch index:  0\n",
      "Epoch 89 MSE =  4.904065\n",
      "batch index:  0\n",
      "Epoch 90 MSE =  4.9026117\n",
      "batch index:  0\n",
      "Epoch 91 MSE =  4.9012356\n",
      "batch index:  0\n",
      "Epoch 92 MSE =  4.899916\n",
      "batch index:  0\n",
      "Epoch 93 MSE =  4.8986826\n",
      "batch index:  0\n",
      "Epoch 94 MSE =  4.8975616\n",
      "batch index:  0\n",
      "Epoch 95 MSE =  4.8964744\n",
      "batch index:  0\n",
      "Epoch 96 MSE =  4.895308\n",
      "batch index:  0\n",
      "Epoch 97 MSE =  4.8942327\n",
      "batch index:  0\n",
      "Epoch 98 MSE =  4.8930635\n",
      "batch index:  0\n",
      "Epoch 99 MSE =  4.891904\n",
      "Minimum error:  4.891904\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#specify the epochs and learning rate\n",
    "n_epochs = 100\n",
    "learning_rate = 0.01\n",
    "batch_size = 20640\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n",
    "#We will want to put the data into a scaled format\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "scaled_housing_data_plus_bias = ss.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "#now we specify our data X and target y as tensor flow constants\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "# now to specify stochastic gradient descent, we must create a set of\n",
    "# random steps\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta, name=\"predictions\")\n",
    "#now specify the error\n",
    "error = y_pred - y\n",
    "\n",
    "#now specify mean squared error\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "#now specify the gradients\n",
    "#gradients = (2/m)*tf.matmul(tf.transpose(X), error)\n",
    "#We could also have coded\n",
    "gradients = tf.gradients(mse,[theta])[0]\n",
    "\n",
    "#now make for a reassignment of theta after each new iteration\n",
    "#training_op = tf.assign(theta, theta - learning_rate*gradients)\n",
    "\n",
    "#OR we could have used (and not even needed a gradients object!)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "#initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#save each mean squared error\n",
    "mses = []\n",
    "\n",
    "#create a function that gets a batch of data from the main data set\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m, size=batch_size) \n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "#now start the session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "            best_theta = theta.eval()\n",
    "            mses.append(mse.eval())\n",
    "            print('batch index: ',batch_index)\n",
    "            print(\"Epoch\", epoch, \"MSE = \",mse.eval())\n",
    "\n",
    "print(\"Minimum error: \",min(mses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have trained your model, you should save it's parameters to disk so you can comeback to it when you want, use it to compare to other models, etc.\n",
    "\n",
    "You probably want to save checkpoints at regular intervals during training, so that if your computer crashes you can return to that point rather than starting over from scratch.\n",
    "\n",
    "Tensor flow makes saving and restoring models very easy. We create a saver node at the end of the construction phase (after all variable nodes are created). Then during the execution phase, just call its save method whenever you want to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%10==0:\n",
    "            save_path = saver.save(sess,\"/tmp/my_model_\"+str(epoch)+\"_.ckpt\")\n",
    "        \n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess,\"/tmp/my_model_final_finished.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore the model, we just perform the restore method of saver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final_finished.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final_finished.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ch9 Problem 12: Logistic regression classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "m = 1000\n",
    "X_moons,y_moons = make_moons(m, noise=0.1, random_state=42)\n",
    "plt.plot(X_moons[y_moons==1,0],X_moons[y_moons==1,1],'go',label=\"+\")\n",
    "plt.plot(X_moons[y_moons==0,0],X_moons[y_moons==0,1],'r^',label=\"-\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(m*test_ratio)\n",
    "X_moons_with_bias = np.c_[np.ones((m,1)),X_moons]\n",
    "y_moons_column_vector = y_moons.reshape(-1,1)\n",
    "\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]\n",
    "X_moons_with_bias = np.c_[np.ones((m,1)),X_moons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#Now create a place to input the data to when training the model using placeholders\n",
    "n_inputs = 2\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs+1),name=\"X\")\n",
    "y = tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m, size=batch_size) \n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "#Now we will be using a batched gradient descent to find the minimized error, so create a variable structure theta\n",
    "#you need a random normal distribution inside theta so these\n",
    "theta = tf.Variable(tf.random_normal([n_inputs+1,1],-1,1,seed=42),name=\"theta\")\n",
    "\n",
    "#Now at each instant we want to make a prediction and modify the error\n",
    "y_lin = tf.matmul(X,theta,name=\"y_lin\")\n",
    "\n",
    "#Now this process is a logitistic regression. How does logistic regression work? \n",
    "# we have a matrix multiplied by a value... then that value is taken exponentially and add 1 to it.\n",
    "#exp = tf.exp(y_lin,name=\"exp\")\n",
    "#y_pred = tf.reciprocal(exp+1, name=\"y_pred\")\n",
    "\n",
    "#we could have also put this into the sigmoid function\n",
    "\n",
    "y_pred = tf.sigmoid(y_lin,name=\"sigmoid\")\n",
    "\n",
    "#Now we have to define a log loss.\n",
    "#then we define a process of putting lowering the error\n",
    "error = tf.losses.log_loss(y,y_pred)\n",
    "\n",
    "#Now specify the learning rate\n",
    "learning_rate = 0.01\n",
    "#now specify the optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(error)\n",
    "\n",
    "#Now initialize global variabls\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.9956636\n",
      "loss:  0.2895711\n",
      "loss:  0.27856556\n",
      "loss:  0.27498057\n",
      "loss:  0.2735479\n",
      "loss:  0.27414542\n",
      "loss:  0.27374113\n",
      "loss:  0.2741371\n",
      "loss:  0.27423912\n",
      "loss:  0.27391765\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "data = X_moons\n",
    "n_batches = int(np.ceil(data.shape[0]/batch_size))\n",
    "\n",
    "def random_batch(X_train,y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0,len(X_train),batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(batch_size):\n",
    "            #fetch a batch at each point\n",
    "            X_batch, y_batch = random_batch(X_train, y_train,batch_size)\n",
    "            #use the session to run the training optimizer\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        loss_val = error.eval({X:X_test,y:y_test})\n",
    "        if epoch%100==0:\n",
    "            print('loss: ',loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem in chapter 9:\n",
    "   * Make a binary classifier using a logistic regression() neural net that can be reused easily.\n",
    "   * Save checkpoints using a saver at regular intervals during training, and save the final model at the end of training.\n",
    "   * Restore the last checkpoint upon startup if training was interrupted\n",
    "   * Define the graph using nice scopes so the graph looks in Tensorboard\n",
    "   * Add summaries to visualize learning curves in tensor board\n",
    "   * Try modifying hyperparameters such as learning rate/batch size and look at the shape of the learning curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the data\n",
    "\n",
    "One technique that might result in better performance is to modify the features and create new ones so that we have polynomial features, such as x**2 and x**3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "import tensorflow as tf\n",
    "m = 1000\n",
    "X_moons,y_moons = make_moons(m, noise=0.1, random_state=42)\n",
    "test_ratio = 0.2\n",
    "test_size = int(m*test_ratio)\n",
    "X_moons_with_bias = np.c_[np.ones((m,1)),X_moons]\n",
    "y_moons_column_vector = y_moons.reshape(-1,1)\n",
    "\n",
    "X_train = X_moons_with_bias[:-test_size]\n",
    "X_test = X_moons_with_bias[-test_size:]\n",
    "y_train = y_moons_column_vector[:-test_size]\n",
    "y_test = y_moons_column_vector[-test_size:]\n",
    "X_moons_with_bias = np.c_[np.ones((m,1)),X_moons]\n",
    "X_train_enhanced = np.c_[X_train, X_train[:,1]**2, X_train[:,2]**2, X_train[:,1]**3, X_train[:,2]**3]\n",
    "X_test_enhanced = np.c_[X_test, X_test[:,1]**2, X_test[:,2]**2, X_test[:,1]**3, X_test[:,2]**3]\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a function that builds the tensor flow graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X,y,initializer=None, seed=42, learning_rate=0.01):\n",
    "    n_inputs_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        \n",
    "        #specify the model\n",
    "        with tf.name_scope(\"model\"):\n",
    "            # we specify an intializer to create a bunch of weights to start with\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform([n_inputs_including_bias,1],-1,1,seed=seed)\n",
    "            theta = tf.Variable(initializer,name=\"theta\")\n",
    "            logits = tf.matmul(X,theta, name=\"logits\")\n",
    "            y_proba = tf.sigmoid(logits)\n",
    "        \n",
    "        #specify the training procedure and loss optimization\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(y,y_proba, scope=\"loss\")\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss',loss)\n",
    "        \n",
    "        #specify the variables initializer\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        \n",
    "        #specify a saver functionality\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "        return y_proba, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specify the function to get the name of the logging directory used to save the summaries of a tensor board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_directory(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += '-'\n",
    "    name = prefix + 'run-'+now\n",
    "    return \"{}/{}\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidePrompt": true
   },
   "source": [
    "Now that we have a function to perform our operations, build a graph using tensor flow ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify inputs and the directory to save model evolution\n",
    "n_inputs = 6\n",
    "logdir = log_directory(\"logreg\")\n",
    "\n",
    "#initalize variables X and y\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs+1),name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None,1), name=\"y\")\n",
    "\n",
    "y_proba, loss, training_op, loss_summary, init, saver = log_reg(X,y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model. Start by checking whether a previousn traing was interrupted, if so load from the checkpoint and continue training from the epoch number we saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f.read() b'15501'\n",
      "Training was interrupted, continuing at epoch  4501\n",
      "INFO:tensorflow:Restoring parameters from /tmp/my_logreg_model.ckpt\n",
      "Epoch: 5000 \t Loss: 0.02971563\n",
      "Epoch: 5500 \t Loss: 0.029370932\n",
      "Epoch: 6000 \t Loss: 0.02903011\n",
      "Epoch: 6500 \t Loss: 0.028709078\n",
      "Epoch: 7000 \t Loss: 0.02845581\n",
      "Epoch: 7500 \t Loss: 0.028137662\n",
      "Epoch: 8000 \t Loss: 0.027918482\n",
      "Epoch: 8500 \t Loss: 0.027613817\n",
      "Epoch: 9000 \t Loss: 0.027371831\n",
      "Epoch: 9500 \t Loss: 0.027152156\n",
      "Epoch: 10000 \t Loss: 0.026939759\n"
     ]
    }
   ],
   "source": [
    "def random_batch(X_train,y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0,len(X_train),batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "import os\n",
    "#specify the number of epochs, batch size and the number of batches\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n",
    "#specify the checkpoint paths for saving. One for checkpoints, one for each epoch and one for the final model\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\"\n",
    "\n",
    "#this is how we load a model from a training point\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        #if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            #this is how we save parts of the file\n",
    "            print(\"f.read()\",f.read())\n",
    "            #start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted, continuing at epoch \", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "    \n",
    "    #start training in from the start epoch, whether it be zero or another point\n",
    "    for epoch in range(start_epoch,n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            \n",
    "            #specify a batch to train with\n",
    "            X_batch, y_batch = random_batch(X_train_enhanced,y_train,batch_size)\n",
    "            \n",
    "            #train by running the training optimizer, feeding the right data\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "            \n",
    "        #evaluate the loss at the end of each epoch, and get a summary string\n",
    "        loss_val,summary_str = sess.run([loss,loss_summary],feed_dict={X:X_test_enhanced,y:y_test})\n",
    "        \n",
    "        #add a summary to the tensor graph\n",
    "        file_writer.add_summary(summary_str,epoch)\n",
    "        \n",
    "        #At every 500 epochs, make an incremental save\n",
    "        if epoch%500==0:\n",
    "            print(\"Epoch:\",epoch, \"\\t Loss:\",loss_val)\n",
    "            saver.save(sess,checkpoint_path)\n",
    "            \n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\"%(epoch+1))\n",
    "    \n",
    "    #at the end of the training, save the model\n",
    "    saver.save(sess, final_model_path)\n",
    "    \n",
    "    #evaluate the probability\n",
    "    y_proba_val = y_proba.eval(feed_dict={X:X_test_enhanced, y:y_test})\n",
    "    \n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to see the precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.9797979797979798\n",
      "Recall:  0.9797979797979798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "y_pred = (y_proba_val >= 0.5)\n",
    "print(\"Precision: \", precision_score(y_pred,y_test))\n",
    "print(\"Recall: \",recall_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(\"Training was interrupted, continuing at epoch \", start_epoch)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(checkpoint_epoch_path):\n",
    "        #if the checkpoint file exists, restore the model and load the epoch number\n",
    "    with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            #this is how we save parts of the file\n",
    "            print(f.read())\n",
    "        print(\"Training was interrupted, continuing at epoch \", start_epoch)\n",
    "        #saver.restore(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
