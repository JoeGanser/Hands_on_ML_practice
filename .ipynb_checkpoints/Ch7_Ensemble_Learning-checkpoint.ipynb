{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,roc_curve,auc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X,y = mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/difference-test-validation-datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "data = ...\n",
    "train, test = split(data)\n",
    " \n",
    "# tune model hyperparameters\n",
    "parameters = ...\n",
    "k = ...\n",
    "for params in parameters:\n",
    "\tskills = list()\n",
    "\tfor i in k:\n",
    "\t\tfold_train, fold_val = cv_split(i, k, train)\n",
    "\t\tmodel = fit(fold_train, params)\n",
    "\t\tskill_estimate = evaluate(model, fold_val)\n",
    "\t\tskills.append(skill_estimate)\n",
    "\tskill = summarize(skills)\n",
    " \n",
    "# evaluate final model for comparison with other models\n",
    "model = fit(train)\n",
    "skill = evaluate(model, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=150, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.9717142857142858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "parameters = {'n_estimators':[50,100,200,300],'max_depth':[None,150]}\n",
    "\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.142857)\n",
    "    \n",
    "scores = {}\n",
    "\n",
    "keys = list(parameters.keys())\n",
    "parameter_list = list(itertools.product(parameters[keys[0]],parameters[keys[1]]))\n",
    "for parameter in parameter_list:\n",
    "    j = parameter[0]\n",
    "    k = parameter[1]\n",
    "    param1 = str(keys[0])+' = '+str(j)\n",
    "    param2 = str(keys[1])+' = '+str(k)\n",
    "    m = RandomForestClassifier(n_estimators=j,max_depth=k)\n",
    "    m.fit(X_train,y_train)\n",
    "    y_pred = m.predict(X_val)\n",
    "    key = param1+' '+param2\n",
    "    scores[key] = accuracy_score(y_pred,y_val)\n",
    "    \n",
    "best = [i for i in list(scores.keys()) if scores[i] == max(scores.values())][0]\n",
    "\n",
    "best1 = ' '.join(best.split(' ')[:3]).split(' = ')[1]\n",
    "best2 = ' '.join(best.split(' ')[3:]).split(' = ')[1]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=int(best1),max_depth=eval(best2))\n",
    "rf.fit(X_train1,y_train1)\n",
    "y_pred_final = rf.predict(X_test)\n",
    "final_score = accuracy_score(y_pred_final,y_test)\n",
    "print(rf)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.001, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "0.9776190476190476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {'C':[0.001,0.01,0.1,1,10],'kernel':['rbf','linear','sigmoid','poly']}\n",
    "\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.142857)\n",
    "    \n",
    "scores = {}\n",
    "\n",
    "keys = list(parameters.keys())\n",
    "parameter_list = list(itertools.product(parameters[keys[0]],parameters[keys[1]]))\n",
    "for parameter in parameter_list:\n",
    "    j = parameter[0]\n",
    "    k = parameter[1]\n",
    "    param1 = str(keys[0])+' = '+str(j)\n",
    "    param2 = str(keys[1])+' = '+str(k)\n",
    "    m = SVC(C=j,kernel=k)\n",
    "    m.fit(X_train,y_train)\n",
    "    y_pred = m.predict(X_val)\n",
    "    key = param1+' '+param2\n",
    "    scores[key] = accuracy_score(y_pred,y_val)\n",
    "    \n",
    "best = [i for i in list(scores.keys()) if scores[i] == max(scores.values())][0]\n",
    "\n",
    "best1 = ' '.join(best.split(' ')[:3]).split(' = ')[1]\n",
    "best2 = ' '.join(best.split(' ')[3:]).split(' = ')[1]\n",
    "\n",
    "svm = SVC(C=float(best1),kernel=(best2))\n",
    "svm.fit(X_train1,y_train1)\n",
    "y_pred_final = svm.predict(X_test)\n",
    "final_score = accuracy_score(y_pred_final,y_test)\n",
    "print(svm)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreeClassifier(class_weight=None, criterion='gini', max_depth=100,\n",
      "          max_features=None, max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, random_state=None,\n",
      "          splitter='random')\n",
      "0.8680476190476191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "parameters = {'max_features':[None,'auto','log2'],'max_depth':[None,50,100,200,500]}\n",
    "\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.142857)\n",
    "    \n",
    "scores = {}\n",
    "\n",
    "keys = list(parameters.keys())\n",
    "parameter_list = list(itertools.product(parameters[keys[0]],parameters[keys[1]]))\n",
    "for parameter in parameter_list:\n",
    "    j = parameter[0]\n",
    "    k = parameter[1]\n",
    "    param1 = str(keys[0])+' = '+str(j)\n",
    "    param2 = str(keys[1])+' = '+str(k)\n",
    "    m = ExtraTreeClassifier(max_features=j,max_depth=k)\n",
    "    m.fit(X_train,y_train)\n",
    "    y_pred = m.predict(X_val)\n",
    "    key = param1+' '+param2\n",
    "    scores[key] = accuracy_score(y_pred,y_val)\n",
    "    \n",
    "best = [i for i in list(scores.keys()) if scores[i] == max(scores.values())][0]\n",
    "\n",
    "best1 = ' '.join(best.split(' ')[:3]).split(' = ')[1]\n",
    "best2 = ' '.join(best.split(' ')[3:]).split(' = ')[1]\n",
    "\n",
    "ET = ExtraTreeClassifier(max_features=eval(best1),max_depth=eval(best2))\n",
    "ET.fit(X_train1,y_train1)\n",
    "y_pred_final = ET.predict(X_test)\n",
    "final_score = accuracy_score(y_pred_final,y_test)\n",
    "print(ET)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET = ExtraTreeClassifier(class_weight='balanced', criterion='gini', max_depth=100,\n",
    "          max_features=None, max_leaf_nodes=None,\n",
    "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "          min_samples_leaf=1, min_samples_split=2,\n",
    "          min_weight_fraction_leaf=0.0, random_state=None,\n",
    "          splitter='random')\n",
    "\n",
    "SV = SVC(C=0.001, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "  kernel='poly', max_iter=-1, probability=True, random_state=None,\n",
    "  shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "RF = RandomForestClassifier(bootstrap=True, class_weight='balanced', criterion='gini',\n",
    "            max_depth=150, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble = VotingClassifier(estimators=[('ET',ET,),('SV',SV),('RF',RF)],voting='soft')\n",
    "ensemble.fit(X_train,y_train)\n",
    "y_en = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.94      0.83      2038\n",
      "         1.0       0.81      0.96      0.88      2350\n",
      "         2.0       0.60      0.87      0.71      2073\n",
      "         3.0       0.61      0.87      0.71      2161\n",
      "         4.0       0.39      0.94      0.55      2063\n",
      "         5.0       0.57      0.78      0.66      1838\n",
      "         6.0       0.83      0.83      0.83      2108\n",
      "         7.0       0.00      0.00      0.00      2210\n",
      "         8.0       0.00      0.00      0.00      2051\n",
      "         9.0       0.00      0.00      0.00      2108\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     21000\n",
      "   macro avg       0.46      0.62      0.52     21000\n",
      "weighted avg       0.46      0.62      0.52     21000\n",
      "\n",
      "0.618\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_en))\n",
    "print(accuracy_score(y_test,y_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
